{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ba4a5064a9e469f9c7ce4326ca9449a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf4430a6c6ad4ce9bd1a7a23628865ba",
              "IPY_MODEL_dff76abb865b43349eb1d81b7169b75d",
              "IPY_MODEL_0b4a5c0494464e6095a3103bf0d13b6b"
            ],
            "layout": "IPY_MODEL_f28eda9ba0ca45518af8d15264be5569"
          }
        },
        "cf4430a6c6ad4ce9bd1a7a23628865ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47a01428563e4f209dc70d676cfdbd66",
            "placeholder": "​",
            "style": "IPY_MODEL_6295440dac024ec3b93b500bc2c0cf57",
            "value": "Computing widget examples:   0%"
          }
        },
        "dff76abb865b43349eb1d81b7169b75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a1cb41905349878cb71833d751f5a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc81c9d84a1d4c338c02b971104cc6fc",
            "value": 1
          }
        },
        "0b4a5c0494464e6095a3103bf0d13b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22a6c3692c54219b160de9702ecc401",
            "placeholder": "​",
            "style": "IPY_MODEL_49fecee4a8a642438dd21acbf08bfba0",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "f28eda9ba0ca45518af8d15264be5569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "47a01428563e4f209dc70d676cfdbd66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6295440dac024ec3b93b500bc2c0cf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7a1cb41905349878cb71833d751f5a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc81c9d84a1d4c338c02b971104cc6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e22a6c3692c54219b160de9702ecc401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49fecee4a8a642438dd21acbf08bfba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnhnEYCPmUmo"
      },
      "outputs": [],
      "source": [
        "!pip -q install sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0VfczVFoJ5b",
        "outputId": "9eea9392-9618-42f1-ddaa-3a630ade7446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 10 15:57:39 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir7ksauZoVNV",
        "outputId": "1b7fe5f4-9da2-47df-b948-1b813d6f3802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.json  sample_data  train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sbert_rank_task5.py\n",
        "import argparse\n",
        "import json\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def load_json(path: str):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def story_key(sample):\n",
        "    return (\n",
        "        sample[\"precontext\"].strip(),\n",
        "        sample[\"sentence\"].strip(),\n",
        "        sample[\"ending\"].strip(),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_story_text(s):\n",
        "    ending = s[\"ending\"].strip()\n",
        "    if ending == \"\":\n",
        "        ending = \"[NO ENDING]\"\n",
        "    return f\"{s['precontext'].strip()} {s['sentence'].strip()} {ending}\"\n",
        "\n",
        "\n",
        "def build_sense_text(s):\n",
        "    ex = s.get(\"example_sentence\", \"\").strip()\n",
        "    if ex:\n",
        "        return f\"{s['judged_meaning'].strip()}. {ex}\"\n",
        "    return s[\"judged_meaning\"].strip()\n",
        "\n",
        "\n",
        "def build_pairs(samples):\n",
        "    \"\"\"\n",
        "    Create training pairs: same story, two senses.\n",
        "    Label = 1 if (story, senseA) should be closer than (story, senseB)\n",
        "    We implement this as a ranking loss using MultipleNegativesRankingLoss:\n",
        "      anchor = story\n",
        "      positive = higher-rated sense\n",
        "      negatives = other senses from batch\n",
        "    \"\"\"\n",
        "    grouped = defaultdict(list)\n",
        "    for s in samples:\n",
        "        grouped[story_key(s)].append(s)\n",
        "\n",
        "    examples = []\n",
        "    skipped = 0\n",
        "    for _, items in grouped.items():\n",
        "        if len(items) < 2:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        items = sorted(items, key=lambda x: float(x[\"average\"]), reverse=True)\n",
        "        a, b = items[0], items[1]\n",
        "\n",
        "        if float(a[\"average\"]) == float(b[\"average\"]):\n",
        "            # no ranking signal\n",
        "            continue\n",
        "\n",
        "        story = build_story_text(a)\n",
        "        pos = build_sense_text(a)   # higher avg\n",
        "        # We only need (anchor, positive) for MultipleNegativesRankingLoss\n",
        "        examples.append(InputExample(texts=[story, pos]))\n",
        "\n",
        "    return examples, skipped\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_spearman(model: SentenceTransformer, samples, batch_size=64):\n",
        "    stories = [build_story_text(s) for s in samples]\n",
        "    senses = [build_sense_text(s) for s in samples]\n",
        "\n",
        "    emb_story = model.encode(stories, batch_size=batch_size, normalize_embeddings=True, convert_to_numpy=True)\n",
        "    emb_sense = model.encode(senses, batch_size=batch_size, normalize_embeddings=True, convert_to_numpy=True)\n",
        "\n",
        "    cos = (emb_story * emb_sense).sum(axis=1)\n",
        "    # Map cosine to [1,5] (rough)\n",
        "    preds = 1.0 + 4.0 * np.clip(cos, 0.0, 1.0)\n",
        "    gold = np.array([float(s[\"average\"]) for s in samples], dtype=float)\n",
        "\n",
        "    sp = spearmanr(preds, gold).correlation\n",
        "    return float(sp), preds\n",
        "\n",
        "\n",
        "def acc_within_sd(preds, samples):\n",
        "    correct = 0\n",
        "    for p, s in zip(preds, samples):\n",
        "        gold = float(s[\"average\"])\n",
        "        sd = float(s[\"stdev\"])\n",
        "        if abs(float(p) - gold) <= max(1.0, sd):\n",
        "            correct += 1\n",
        "    return correct / len(samples)\n",
        "\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--train\", default=\"train.json\")\n",
        "    ap.add_argument(\"--dev\", default=\"dev.json\")\n",
        "    ap.add_argument(\"--model\", default=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    ap.add_argument(\"--epochs\", type=int, default=3)\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    ap.add_argument(\"--lr\", type=float, default=2e-5)\n",
        "    ap.add_argument(\"--seed\", type=int, default=42)\n",
        "    ap.add_argument(\"--out_dir\", default=\"sbert_out\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    train_data = list(load_json(args.train).values())\n",
        "    dev_data = list(load_json(args.dev).values())\n",
        "\n",
        "    train_examples, skipped = build_pairs(train_data)\n",
        "    print(f\"Train rows: {len(train_data)} | Train examples: {len(train_examples)} | skipped groups: {skipped}\")\n",
        "\n",
        "    model = SentenceTransformer(args.model, device=device)\n",
        "\n",
        "    train_loader = DataLoader(train_examples, shuffle=True, batch_size=args.batch_size, drop_last=True)\n",
        "\n",
        "    # Ranking-style loss: story should be close to correct sense vs other senses in batch\n",
        "    train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "    # Evaluate before training\n",
        "    sp0, preds0 = eval_spearman(model, dev_data)\n",
        "    acc0 = acc_within_sd(preds0, dev_data)\n",
        "    print(f\"[BEFORE] Spearman={sp0:.4f} | Acc@SD={acc0:.4f}\")\n",
        "\n",
        "    warmup_steps = int(len(train_loader) * args.epochs * 0.1)\n",
        "\n",
        "    model.fit(\n",
        "        train_objectives=[(train_loader, train_loss)],\n",
        "        epochs=args.epochs,\n",
        "        warmup_steps=warmup_steps,\n",
        "        optimizer_params={\"lr\": args.lr},\n",
        "        output_path=args.out_dir,\n",
        "        show_progress_bar=True\n",
        "    )\n",
        "\n",
        "    # Load best saved model\n",
        "    best_model = SentenceTransformer(args.out_dir, device=device)\n",
        "    sp, preds = eval_spearman(best_model, dev_data)\n",
        "    acc = acc_within_sd(preds, dev_data)\n",
        "    print(f\"[FINAL] Spearman={sp:.6f} | Acc@SD={acc:.6f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohQzP3OkouWC",
        "outputId": "9045e94d-77fb-461a-a974-5727a9edd48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sbert_rank_task5.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python sbert_rank_task5.py --train train.json --dev dev.json --epochs 5 --batch_size 32\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aNbAFoKpayW",
        "outputId": "f29326a0-7dc3-4091-9a14-c5abf4b9b269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-10 16:05:49.392485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768061149.427979    2608 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768061149.438504    2608 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768061149.464670    2608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768061149.464710    2608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768061149.464719    2608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768061149.464725    2608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-10 16:05:49.472396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Device: cuda\n",
            "Train rows: 2280 | Train examples: 1112 | skipped groups: 0\n",
            "[BEFORE] Spearman=0.2385 | Acc@SD=0.5697\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20260110_160637-gdpitezb\u001b[0m\n",
            "{'train_runtime': 56.9476, 'train_samples_per_second': 95.526, 'train_steps_per_second': 2.985, 'train_loss': 0.4711122849408318, 'epoch': 5.0}\n",
            "100% 170/170 [00:19<00:00,  8.81it/s]\n",
            "[FINAL] Spearman=0.198491 | Acc@SD=0.576531\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20260110_160637-gdpitezb\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20260110_160637-gdpitezb/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U sentence-transformers scipy scikit-learn\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, InputExample\n",
        "from sentence_transformers.losses import CosineSimilarityLoss\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "TRAIN_PATH = \"train.json\"\n",
        "DEV_PATH   = \"dev.json\"\n",
        "\n",
        "def load_json(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def build_story_text(s):\n",
        "    ending = s.get(\"ending\", \"\").strip()\n",
        "    if ending == \"\":\n",
        "        ending = \"[NO ENDING]\"\n",
        "    return f\"{s['precontext'].strip()} {s['sentence'].strip()} {ending}\"\n",
        "\n",
        "def build_sense_text(s):\n",
        "    ex = s.get(\"example_sentence\", \"\").strip()\n",
        "    if ex:\n",
        "        return f\"{s['judged_meaning'].strip()}. {ex}\"\n",
        "    return s[\"judged_meaning\"].strip()\n",
        "\n",
        "def scale_1to5_to_0to1(y):\n",
        "    # cosine similarity loss expects targets in [-1,1] usually, but [0,1] works well for normalized embeddings\n",
        "    y = float(y)\n",
        "    return (y - 1.0) / 4.0\n",
        "\n",
        "def accuracy_within_sd(preds, samples):\n",
        "    correct = 0\n",
        "    for p, s in zip(preds, samples):\n",
        "        gold = float(s[\"average\"])\n",
        "        sd = float(s[\"stdev\"])\n",
        "        if abs(p - gold) <= max(1.0, sd):\n",
        "            correct += 1\n",
        "    return correct / len(samples)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dev_samples, batch_size=64):\n",
        "    stories = [build_story_text(s) for s in dev_samples]\n",
        "    senses  = [build_sense_text(s) for s in dev_samples]\n",
        "\n",
        "    story_emb = model.encode(stories, batch_size=batch_size, convert_to_tensor=True,\n",
        "                             normalize_embeddings=True, show_progress_bar=False)\n",
        "    sense_emb = model.encode(senses, batch_size=batch_size, convert_to_tensor=True,\n",
        "                             normalize_embeddings=True, show_progress_bar=False)\n",
        "\n",
        "    cos = (story_emb * sense_emb).sum(dim=1).cpu().numpy()\n",
        "\n",
        "    # map cosine in [-1,1] to 1..5\n",
        "    preds = 1.0 + 4.0 * ((cos + 1.0) / 2.0)\n",
        "    gold  = np.array([float(s[\"average\"]) for s in dev_samples])\n",
        "\n",
        "    sp = spearmanr(preds, gold).correlation\n",
        "    acc = accuracy_within_sd(preds, dev_samples)\n",
        "    return float(sp), float(acc)\n",
        "\n",
        "train_data = load_json(TRAIN_PATH)\n",
        "dev_data   = load_json(DEV_PATH)\n",
        "\n",
        "train_samples = list(train_data.values())\n",
        "dev_samples   = list(dev_data.values())\n",
        "\n",
        "train_examples = [\n",
        "    InputExample(\n",
        "        texts=[build_story_text(s), build_sense_text(s)],\n",
        "        label=scale_1to5_to_0to1(s[\"average\"])\n",
        "    )\n",
        "    for s in train_samples\n",
        "]\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=DEVICE)\n",
        "\n",
        "train_loader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
        "train_loss = CosineSimilarityLoss(model)\n",
        "\n",
        "# Before training\n",
        "sp0, acc0 = evaluate(model, dev_samples)\n",
        "print(f\"[BEFORE] Spearman={sp0:.4f} | Acc@SD={acc0:.4f}\")\n",
        "\n",
        "# Train\n",
        "model.fit(\n",
        "    train_objectives=[(train_loader, train_loss)],\n",
        "    epochs=5,\n",
        "    warmup_steps=100,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "# After training\n",
        "sp, acc = evaluate(model, dev_samples)\n",
        "print(f\"[FINAL] Spearman={sp:.6f} | Acc@SD={acc:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464,
          "referenced_widgets": [
            "6ba4a5064a9e469f9c7ce4326ca9449a",
            "cf4430a6c6ad4ce9bd1a7a23628865ba",
            "dff76abb865b43349eb1d81b7169b75d",
            "0b4a5c0494464e6095a3103bf0d13b6b",
            "f28eda9ba0ca45518af8d15264be5569",
            "47a01428563e4f209dc70d676cfdbd66",
            "6295440dac024ec3b93b500bc2c0cf57",
            "c7a1cb41905349878cb71833d751f5a5",
            "fc81c9d84a1d4c338c02b971104cc6fc",
            "e22a6c3692c54219b160de9702ecc401",
            "49fecee4a8a642438dd21acbf08bfba0"
          ]
        },
        "id": "E0hiSbI5qzch",
        "outputId": "6e22bdfb-b926-425c-c9e3-2c4aa79faec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/8.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m7.5/8.9 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDevice: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BEFORE] Spearman=0.2385 | Acc@SD=0.5884\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ba4a5064a9e469f9c7ce4326ca9449a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260110_160946-1b56fdkd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 00:40, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FINAL] Spearman=0.447844 | Acc@SD=0.591837\n"
          ]
        }
      ]
    }
  ]
}